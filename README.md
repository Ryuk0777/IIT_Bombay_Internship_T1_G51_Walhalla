# Multimodal Cognitive Response Time Prediction

**Predicting studentsâ€™ response times using EEG, eye-tracking, motion, and psychometric data.**

---

## ğŸ“– Table of Contents

1. [Project Overview](#-project-overview)
2. [Dataset Description](#-dataset-description)
3. [Motivation](#-motivation)
4. [Methodology](#-methodology)
5. [Data Processing & Feature Engineering](#-data-processing--feature-engineering)
6. [Model Development](#-model-development)
7. [Results & Performance](#-results--performance)
8. [Project Pipeline Diagram](#-project-pipeline-ascii-diagram)
9. [Hardware & Training Environment](#ï¸-hardware--training-environment)
10. [Repository Structure](#-repository-structure)
11. [How to Run Locally](#-how-to-run-locally)
12. [Challenges & Learnings](#-challenges--learnings)
13. [Future Work](#-future-work)
14. [ References](#-references)
15. [License](#-license)

---

## ğŸ§© Project Overview

This project focuses on building an artificial intelligence system to **predict student response times** during cognitive tasks using **multimodal sensor data** â€” including EEG (brainwave), eye-tracking, and psychometric logs.

The goal is to model the relationship between neural activity, behavioral signals, and task difficulty to understand cognitive effort and reaction patterns.


---

## ğŸ§  Dataset Description

**Dataset Title:** *A Multisensor Dataset of South Asian Post-Graduate Students Working on Mental Rotation Tasks*
**Authors:** Ashwin T. S., Suraj Ranganath, Kabyashree Khanikar, Karishma Khan, Ramkumar Rajendran, Ritayan Mitra
**DOI:** [https://doi.org/10.6084/m9.figshare.28120670.v1](https://doi.org/10.6084/m9.figshare.28120670.v1)

### Summary:

* **Subjects:** 38 post-graduate students
* **Sensors Used:** EEG, Eye-Tracking, IVT, Psychometric, Accelerometer, Gyroscope
* **Task:** Mental rotation cognitive activity

Each trial corresponds to a unique `QuestionKey` with features describing neural activity, gaze behavior, motion patterns, and subjective difficulty.

---

## ğŸ¯ Motivation

Traditional learning analytics systems focus on grades, scores, or completion time â€” which do not reflect real cognitive effort or mental workload.

This project explores **how physiological and behavioral signals can predict response times**, offering insights for adaptive learning systems that react to studentsâ€™ cognitive states.

---

## ğŸ§® Methodology

### Type-1: Question-level Aggregation

Data aggregated by `QuestionKey` (one record per question).
Baseline models (Random Forest, XGBoost) used to estimate response time from averaged features.

* **Mean RÂ²:** 0.51 â€“ 0.65

---

### Type-2: Second-level Temporal Features

Data aggregated by `Second`.
Created time-based and temporal summary features such as:

* Per-second gaze averages
* Fixation/saccade ratios
* EEG band averages (Î”, Î¸, Î±, Î², Î³)
* Per-question spectral mean features

Saved the new engineered dataset as *Type-2 features*, later used for deep learning.

* **Mean RÂ² (XGBoost GPU):** 0.78

---

### Type-3: Deep Temporal Modeling

Used sequence modeling to capture second-wise temporal dependencies.

* Input shape: `(samples, sequence_length, features)`
* Sequence length (`seq_len`): 10â€“30 seconds
* Architectures: **Temporal CNN** and **BiLSTM**
* Validation: **Group K-Fold** (5 splits to prevent cross-student leakage)

**Best Model:** BiLSTM

* **Mean RÂ²:** 0.98
* **MAE:** ~1.6 seconds

---

## ğŸ§° Data Processing & Feature Engineering

### Preprocessing Steps:

* Removed trials with missing or invalid `ResponseTime`
* Filtered out idle seconds and missing `QuestionKey`
* Aligned EEG, EYE, IVT, and PSY using `UnixTime`
* Handled NaN / -1 sentinel values
* Scaled features using `StandardScaler`

### Engineered Features:

| Category            | Features                                               |
| ------------------- | ------------------------------------------------------ |
| EEG Bands           | Delta, Theta, Alpha, Beta, Gamma (raw + averaged)      |
| Eye                 | Gaze X/Y variance, fixation/saccade ratios, dispersion |
| Motion              | Accelerometer X/Y/Z, Gyroscope X/Y/Z                   |
| Psychometric        | Difficulty, QuestionKey, ResponseTime                  |
| Temporal Aggregates | Per-second and per-question means                      |

---

## ğŸ§  Model Development

| Model         | Type             | Key Features            | Mean RÂ²   | Notes                                    |
| ------------- | ---------------- | ----------------------- | --------- | ---------------------------------------- |
| Random Forest | Tree-based       | QuestionKey Aggregation | 0.51      | Baseline                                 |
| XGBoost       | Tree-based (GPU) | Temporal + Difficulty   | 0.65â€“0.78 | Tuned via RandomizedSearchCV             |
| Temporal CNN  | Deep Learning    | Sequential Second Data  | 0.94      | Captures local time patterns             |
| BiLSTM        | Deep Learning    | Sequential Second Data  | **0.98**  | Captures long-term temporal dependencies |

---

## ğŸ“Š Results & Performance

### Overall Results:

| Model         | Mean RÂ²    | MAE    | Validation Type |
| ------------- | ---------- | ------ | --------------- |
| BiLSTM        | **0.9829** | ~1.6 s | GroupKFold (5)  |
| Temporal CNN  | 0.945      | ~1.8 s | GroupKFold (5)  |
| XGBoost (GPU) | 0.656      | ~2.9 s | GroupKFold (5)  |

---

## ğŸ“Š Project Pipeline (ASCII Diagram)

```
                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚        Raw Sensor Data  â”‚
                                                â”‚  EEG | EYE | IVT | PSY  â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                              â”‚
                                                              â–¼
                                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                             â”‚  Data Cleaning & Alignment   â”‚
                                             â”‚ (UnixTime Sync, Idle Removal)â”‚
                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                              â”‚
                                                              â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚                   FEATURE AGGREGATION                        â”‚
                              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                              â”‚  TYPE-1: Question-Level Aggregation                          â”‚
                              â”‚   - Aggregate per QuestionKey                                â”‚
                              â”‚   - Features: EEG bands, gaze stats, difficulty              â”‚
                              â”‚   - Models: Linear, RF, XGBoost                              â”‚
                              â”‚   - RÂ² â‰ˆ 0.51-0.65                                           â”‚
                              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                              â”‚  TYPE-2: Second-Level Temporal Features                      â”‚
                              â”‚   - Aggregate per Second                                     â”‚
                              â”‚   - Add temporal features: gaze averages, band means         â”‚
                              â”‚   - Models: RF, XGBoost (GPU)                                â”‚
                              â”‚   - RÂ² â‰ˆ 0.65-0.78                                           â”‚
                              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                              â”‚  TYPE-3: Deep Temporal Modeling                              â”‚
                              â”‚   - Sequence creation (seq_len = 10-30 s)                    â”‚
                              â”‚   - Models: Temporal CNN, BiLSTM                             â”‚
                              â”‚   - RÂ² â‰ˆ 0.94-0.98                                           â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                            â”‚
                                                            â–¼
                                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                             â”‚   Response Time Prediction   â”‚
                                             â”‚  (Regression Output, MAEâ‰ˆ1.6)â”‚
                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Hardware & Training Environment

| Component                     | Specification                                            |
| ----------------------------- | -------------------------------------------------------- |
| **CPU**                       | Intel Core i5-14600K (14 cores, 20 threads)              |
| **GPU**                       | NVIDIA RTX 5070 (12 GB  GDDR7 VRAM)                            |
| **RAM**                       | 32 GB DDR5 (6000 MHz)                                    |
| **OS**                        | Ubuntu 22.04 LTS                                         |
| **Frameworks**                | Python 3.12, TensorFlow 2.x, Scikit-learn, XGBoost (GPU) |
| **RAM Usage During Training** | ~22 GB                                                   |

**GPU Acceleration:**
Used for both **XGBoost (tree_method = hist)** and **deep learning** training to reduce training time and handle large-scale feature tensors efficiently.

---

## ğŸ§± Repository Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Raw sensor data (EEG, EYE, IVT, PSY)
â”‚   â”œâ”€â”€ processed/                  # Cleaned and merged data
â”‚   â””â”€â”€ feature_engineered/         # Type-1 and Type-2 feature data
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_type1_baseline.ipynb
â”‚   â”œâ”€â”€ 02_type2_feature_engineering.ipynb
â”‚   â””â”€â”€ 03_type3_deep_models.ipynb
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ xgb_model_tuned.joblib
â”‚   â”œâ”€â”€ temporal_cnn_model.h5
â”‚   â””â”€â”€ bilstm_model.h5
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§ª How to Run Locally

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/Ryuk0777/IIT_Bombay_Internship_T1_G51_Walhalla.git
cd IIT_Bombay_Internship_T1_G51_Walhalla
```

### 2ï¸âƒ£ Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate      # Linux/Mac
venv\Scripts\activate         # Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

open notebooks to explore step-by-step:

* Type-1 Baseline (Classical ML)
* Type-2 Feature Engineering
* Type-3 Deep Models

---

## ğŸš§ Challenges & Learnings

### Challenges:

* High memory consumption during aggregation (~22 GB RAM)
* Long CPU-based training times
* Synchronizing multimodal signals with missing timestamps
* Avoiding feature leakage across students

### Learnings:

* Second-level aggregation revealed strong temporal patterns
* GPU acceleration (RTX 5070) drastically reduced model training time
* Proper grouping by students (GroupKFold) is essential for realistic evaluation

---

## ğŸš€ Future Work

* Real-time inference pipeline for live EEG and eye-tracking data
* Deploy as an interactive FastAPI service
* Model optimization using ONNX Runtime and TensorRT
* Cognitive analytics dashboard for educators

---


## ğŸ“˜ References

1. T. S. Ashwin et al., *A Multisensor Dataset of South Asian Post-Graduate Students Working on Mental Rotation Tasks*, Scientific Data (2025). [DOI:10.1038/s41597-025-04865-5](https://doi.org/10.1038/s41597-025-04865-5)
2. Dataset DOI: [https://doi.org/10.6084/m9.figshare.28120670.v1](https://doi.org/10.6084/m9.figshare.28120670.v1)


---

## ğŸ“œ License

Released under the **MIT License**.
You are free to use, modify, and distribute with attribution.









